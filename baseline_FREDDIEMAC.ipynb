{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# SRC_PATH = '/content/gdrive/MyDrive/MP FEB/Colab'\n",
    "# sys.path.append(SRC_PATH)\n",
    "\n",
    "# !pip install wandb -qqq\n",
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "# wandb.init(\n",
    "#     # Set the project where this run will be logged\n",
    "#     project=\"baseline_poc\", \n",
    "#     # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "#     #name=\"experiment 1\"\n",
    "#     # Track hyperparameters and run metadata\n",
    "#     #config={\n",
    "#       #\"learning_rate\": 0.02,\n",
    "#       #\"architecture\": \"CNN\",\n",
    "#       #\"dataset\": \"CIFAR-100\",\n",
    "#       #\"epochs\": 10,}\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = str(os.getcwd()) + \"\\data\"\n",
    "\n",
    "blumenstock_types = {'LOAN_SEQUENCE_NUMBER': str, 'INT_RATE': float, 'ORIG_UPB': float, 'FICO_SCORE': float,\n",
    "                    'DTI_R': float, 'LTV_R': float, 'FIRST_PAYMENT_DATE': str, 'BAL_REPAID': float, 'T_ACT_12M': float, 'T_DEL_30D': float, \n",
    "                    'T_DEL_60D': float, 'LABEL': float, 'REMAINING_MONTHS_TO_LEGAL_MATURITY': float, \"TIME_TO_EVENT\": float, 'TOTAL_OBSERVED_LENGTH': float}\n",
    "\n",
    "\n",
    "df_blumenstock = dd.read_parquet(data_folder + \"./blumenstock_labeled_sample_orig_*.parquet.gzip\")\n",
    "df_blumenstock = df_blumenstock.astype(blumenstock_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN_SEQUENCE_NUMBER</th>\n",
       "      <th>INT_RATE</th>\n",
       "      <th>ORIG_UPB</th>\n",
       "      <th>FICO_SCORE</th>\n",
       "      <th>DTI_R</th>\n",
       "      <th>LTV_R</th>\n",
       "      <th>FIRST_PAYMENT_DATE</th>\n",
       "      <th>REMAINING_MONTHS_TO_LEGAL_MATURITY</th>\n",
       "      <th>TOTAL_OBSERVED_LENGTH</th>\n",
       "      <th>TIME_TO_EVENT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>BAL_REPAID</th>\n",
       "      <th>T_ACT_12M</th>\n",
       "      <th>T_DEL_30D</th>\n",
       "      <th>T_DEL_60D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F10Q10000014</td>\n",
       "      <td>4.375</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>201005</td>\n",
       "      <td>156.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901226</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F10Q10000069</td>\n",
       "      <td>4.500</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>156.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836209</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F10Q10000089</td>\n",
       "      <td>4.500</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>120.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724131</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F10Q10000115</td>\n",
       "      <td>4.500</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>115.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711440</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F10Q10000302</td>\n",
       "      <td>4.375</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>143.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844081</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F10Q10000332</td>\n",
       "      <td>4.750</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>62.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073537</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F10Q10000658</td>\n",
       "      <td>4.000</td>\n",
       "      <td>361000.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>145.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847537</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F10Q10000681</td>\n",
       "      <td>4.375</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>67.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344512</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F10Q10000913</td>\n",
       "      <td>4.375</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>98.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596179</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F10Q10000944</td>\n",
       "      <td>4.375</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>201003</td>\n",
       "      <td>113.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677846</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOAN_SEQUENCE_NUMBER  INT_RATE  ORIG_UPB  FICO_SCORE  DTI_R  LTV_R  \\\n",
       "0         F10Q10000014     4.375  216000.0       784.0   38.0   80.0   \n",
       "1         F10Q10000069     4.500  200000.0       795.0   35.0   67.0   \n",
       "2         F10Q10000089     4.500  146000.0       784.0   47.0   55.0   \n",
       "3         F10Q10000115     4.500   68000.0       794.0   30.0   55.0   \n",
       "4         F10Q10000302     4.375  250000.0       726.0   55.0   60.0   \n",
       "5         F10Q10000332     4.750   70000.0       760.0   24.0   42.0   \n",
       "6         F10Q10000658     4.000  361000.0       755.0   44.0   57.0   \n",
       "7         F10Q10000681     4.375  124000.0       719.0   45.0   80.0   \n",
       "8         F10Q10000913     4.375  165000.0       721.0   35.0   59.0   \n",
       "9         F10Q10000944     4.375  142000.0       792.0   10.0   32.0   \n",
       "\n",
       "  FIRST_PAYMENT_DATE  REMAINING_MONTHS_TO_LEGAL_MATURITY  \\\n",
       "0             201005                               156.0   \n",
       "1             201003                               156.0   \n",
       "2             201003                               120.0   \n",
       "3             201003                               115.0   \n",
       "4             201003                               143.0   \n",
       "5             201003                                62.0   \n",
       "6             201003                               145.0   \n",
       "7             201003                                67.0   \n",
       "8             201003                                98.0   \n",
       "9             201003                               113.0   \n",
       "\n",
       "   TOTAL_OBSERVED_LENGTH  TIME_TO_EVENT  LABEL  BAL_REPAID  T_ACT_12M  \\\n",
       "0                   25.0           25.0    0.0    0.901226       12.0   \n",
       "1                   25.0           25.0    0.0    0.836209       12.0   \n",
       "2                   61.0           61.0    0.0    0.724131       12.0   \n",
       "3                   66.0           66.0    0.0    0.711440       12.0   \n",
       "4                   38.0           38.0    0.0    0.844081       12.0   \n",
       "5                  119.0          119.0    0.0    0.073537       12.0   \n",
       "6                   36.0           36.0    0.0    0.847537       12.0   \n",
       "7                  114.0          114.0    0.0    0.344512       12.0   \n",
       "8                   83.0           83.0    0.0    0.596179       12.0   \n",
       "9                   68.0           68.0    0.0    0.677846       12.0   \n",
       "\n",
       "   T_DEL_30D  T_DEL_60D  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "5        0.0        0.0  \n",
       "6        0.0        0.0  \n",
       "7        0.0        0.0  \n",
       "8        0.0        0.0  \n",
       "9        0.0        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blumenstock.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalising raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_to_normalise = ['INT_RATE', 'ORIG_UPB', 'FICO_SCORE', 'DTI_R', 'LTV_R', 'REMAINING_MONTHS_TO_LEGAL_MATURITY',\n",
    "                           'BAL_REPAID', 'T_ACT_12M', 'T_DEL_30D', 'T_DEL_60D']\n",
    "\n",
    "df_blumenstoch_mean = df_blumenstock[covariates_to_normalise].mean().compute()\n",
    "df_blumenstoch_std = df_blumenstock[covariates_to_normalise].std().compute()\n",
    "\n",
    "df_blumenstock[covariates_to_normalise] = (df_blumenstock[covariates_to_normalise] - df_blumenstoch_mean) / df_blumenstoch_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN_SEQUENCE_NUMBER</th>\n",
       "      <th>INT_RATE</th>\n",
       "      <th>ORIG_UPB</th>\n",
       "      <th>FICO_SCORE</th>\n",
       "      <th>DTI_R</th>\n",
       "      <th>LTV_R</th>\n",
       "      <th>FIRST_PAYMENT_DATE</th>\n",
       "      <th>REMAINING_MONTHS_TO_LEGAL_MATURITY</th>\n",
       "      <th>TOTAL_OBSERVED_LENGTH</th>\n",
       "      <th>TIME_TO_EVENT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>BAL_REPAID</th>\n",
       "      <th>T_ACT_12M</th>\n",
       "      <th>T_DEL_30D</th>\n",
       "      <th>T_DEL_60D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F10Q10000014</td>\n",
       "      <td>0.657758</td>\n",
       "      <td>0.479923</td>\n",
       "      <td>0.261876</td>\n",
       "      <td>-0.661558</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>201005</td>\n",
       "      <td>1.082756</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142886</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F10Q10000069</td>\n",
       "      <td>0.930986</td>\n",
       "      <td>0.318299</td>\n",
       "      <td>0.410433</td>\n",
       "      <td>-0.668209</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>201003</td>\n",
       "      <td>1.082756</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926180</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F10Q10000089</td>\n",
       "      <td>0.930986</td>\n",
       "      <td>-0.227181</td>\n",
       "      <td>0.261876</td>\n",
       "      <td>-0.641604</td>\n",
       "      <td>-0.274923</td>\n",
       "      <td>201003</td>\n",
       "      <td>0.233697</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552615</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F10Q10000115</td>\n",
       "      <td>0.930986</td>\n",
       "      <td>-1.015098</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>-0.679295</td>\n",
       "      <td>-0.274923</td>\n",
       "      <td>201003</td>\n",
       "      <td>0.115772</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F10Q10000302</td>\n",
       "      <td>0.657758</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>-0.521425</td>\n",
       "      <td>-0.623868</td>\n",
       "      <td>-0.030371</td>\n",
       "      <td>201003</td>\n",
       "      <td>0.776151</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952417</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F10Q10000332</td>\n",
       "      <td>1.477441</td>\n",
       "      <td>-0.994895</td>\n",
       "      <td>-0.062248</td>\n",
       "      <td>-0.692597</td>\n",
       "      <td>-0.910756</td>\n",
       "      <td>201003</td>\n",
       "      <td>-1.134232</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.615867</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F10Q10000658</td>\n",
       "      <td>-0.161925</td>\n",
       "      <td>1.944640</td>\n",
       "      <td>-0.129774</td>\n",
       "      <td>-0.648256</td>\n",
       "      <td>-0.177102</td>\n",
       "      <td>201003</td>\n",
       "      <td>0.823321</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963936</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F10Q10000681</td>\n",
       "      <td>0.657758</td>\n",
       "      <td>-0.449414</td>\n",
       "      <td>-0.615961</td>\n",
       "      <td>-0.646039</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>201003</td>\n",
       "      <td>-1.016307</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712686</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F10Q10000913</td>\n",
       "      <td>0.657758</td>\n",
       "      <td>-0.035253</td>\n",
       "      <td>-0.588951</td>\n",
       "      <td>-0.668209</td>\n",
       "      <td>-0.079282</td>\n",
       "      <td>201003</td>\n",
       "      <td>-0.285173</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126142</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F10Q10000944</td>\n",
       "      <td>0.657758</td>\n",
       "      <td>-0.267587</td>\n",
       "      <td>0.369917</td>\n",
       "      <td>-0.723636</td>\n",
       "      <td>-1.399858</td>\n",
       "      <td>201003</td>\n",
       "      <td>0.068602</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398345</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>-0.123631</td>\n",
       "      <td>-0.067393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOAN_SEQUENCE_NUMBER  INT_RATE  ORIG_UPB  FICO_SCORE     DTI_R     LTV_R  \\\n",
       "0         F10Q10000014  0.657758  0.479923    0.261876 -0.661558  0.947833   \n",
       "1         F10Q10000069  0.930986  0.318299    0.410433 -0.668209  0.312000   \n",
       "2         F10Q10000089  0.930986 -0.227181    0.261876 -0.641604 -0.274923   \n",
       "3         F10Q10000115  0.930986 -1.015098    0.396928 -0.679295 -0.274923   \n",
       "4         F10Q10000302  0.657758  0.823374   -0.521425 -0.623868 -0.030371   \n",
       "5         F10Q10000332  1.477441 -0.994895   -0.062248 -0.692597 -0.910756   \n",
       "6         F10Q10000658 -0.161925  1.944640   -0.129774 -0.648256 -0.177102   \n",
       "7         F10Q10000681  0.657758 -0.449414   -0.615961 -0.646039  0.947833   \n",
       "8         F10Q10000913  0.657758 -0.035253   -0.588951 -0.668209 -0.079282   \n",
       "9         F10Q10000944  0.657758 -0.267587    0.369917 -0.723636 -1.399858   \n",
       "\n",
       "  FIRST_PAYMENT_DATE  REMAINING_MONTHS_TO_LEGAL_MATURITY  \\\n",
       "0             201005                            1.082756   \n",
       "1             201003                            1.082756   \n",
       "2             201003                            0.233697   \n",
       "3             201003                            0.115772   \n",
       "4             201003                            0.776151   \n",
       "5             201003                           -1.134232   \n",
       "6             201003                            0.823321   \n",
       "7             201003                           -1.016307   \n",
       "8             201003                           -0.285173   \n",
       "9             201003                            0.068602   \n",
       "\n",
       "   TOTAL_OBSERVED_LENGTH  TIME_TO_EVENT  LABEL  BAL_REPAID  T_ACT_12M  \\\n",
       "0                   25.0           25.0    0.0    1.142886   0.119319   \n",
       "1                   25.0           25.0    0.0    0.926180   0.119319   \n",
       "2                   61.0           61.0    0.0    0.552615   0.119319   \n",
       "3                   66.0           66.0    0.0    0.510314   0.119319   \n",
       "4                   38.0           38.0    0.0    0.952417   0.119319   \n",
       "5                  119.0          119.0    0.0   -1.615867   0.119319   \n",
       "6                   36.0           36.0    0.0    0.963936   0.119319   \n",
       "7                  114.0          114.0    0.0   -0.712686   0.119319   \n",
       "8                   83.0           83.0    0.0    0.126142   0.119319   \n",
       "9                   68.0           68.0    0.0    0.398345   0.119319   \n",
       "\n",
       "   T_DEL_30D  T_DEL_60D  \n",
       "0  -0.123631  -0.067393  \n",
       "1  -0.123631  -0.067393  \n",
       "2  -0.123631  -0.067393  \n",
       "3  -0.123631  -0.067393  \n",
       "4  -0.123631  -0.067393  \n",
       "5  -0.123631  -0.067393  \n",
       "6  -0.123631  -0.067393  \n",
       "7  -0.123631  -0.067393  \n",
       "8  -0.123631  -0.067393  \n",
       "9  -0.123631  -0.067393  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blumenstock.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset will contain 6154 samples\n",
      "This dataloader will deliver 24 batches\n",
      "torch.Size([256, 1, 10])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from FREDDIEMAC_baseline_data import FREDDIEMAC_basline_dataset, FREDDIEMAC_dataloader\n",
    "\n",
    "BATCH_SIZE = 2**8\n",
    "\n",
    "frac_cases=0.25\n",
    "test_set = False\n",
    "augment = False\n",
    "data_augment_factor = 3\n",
    "random_state = 42\n",
    "\n",
    "allowed_covariates = ['INT_RATE', 'ORIG_UPB', 'FICO_SCORE', 'DTI_R','LTV_R', 'BAL_REPAID', \n",
    "                     'T_ACT_12M', 'T_DEL_30D', 'T_DEL_60D', 'REMAINING_MONTHS_TO_LEGAL_MATURITY']\n",
    "\n",
    "TIME_TO_EVENT_covariate = 'TIME_TO_EVENT'\n",
    "LABEL_covariate = 'LABEL'\n",
    "\n",
    "\n",
    "FREDDIEMAC_raw_dataset = FREDDIEMAC_basline_dataset(df_blumenstock, \n",
    "                                                    allowed_covariates,\n",
    "                                                    TIME_TO_EVENT_covariate,\n",
    "                                                    LABEL_covariate,\n",
    "                                                    frac_cases,\n",
    "                                                    random_state,\n",
    "                                                    test_set,\n",
    "                                                    augment,\n",
    "                                                    data_augment_factor)\n",
    "\n",
    "print(\"This dataset will contain %d samples\" % len(FREDDIEMAC_raw_dataset))\n",
    "\n",
    "data_loader = FREDDIEMAC_dataloader(dataset=FREDDIEMAC_raw_dataset,\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"This dataloader will deliver %d batches\" % data_loader.get_max_iterations())\n",
    "\n",
    "batch_data, batch_data_length, batch_event, batch_tte = next(data_loader)\n",
    "\n",
    "print(batch_data.shape)\n",
    "print(batch_data_length.shape)\n",
    "print(batch_event.shape)\n",
    "print(batch_tte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch event= 0 --- batch_data_length= 114 --- batch_tte= 114\n",
      "batch event= 0 --- batch_data_length= 20 --- batch_tte= 20\n",
      "batch event= 0 --- batch_data_length= 123 --- batch_tte= 123\n",
      "batch event= 0 --- batch_data_length= 74 --- batch_tte= 74\n",
      "batch event= 0 --- batch_data_length= 80 --- batch_tte= 80\n",
      "batch event= 3 --- batch_data_length= 143 --- batch_tte= 143\n",
      "batch event= 0 --- batch_data_length= 16 --- batch_tte= 16\n",
      "batch event= 0 --- batch_data_length= 36 --- batch_tte= 36\n",
      "batch event= 0 --- batch_data_length= 27 --- batch_tte= 27\n",
      "batch event= 3 --- batch_data_length= 143 --- batch_tte= 143\n",
      "batch event= 0 --- batch_data_length= 141 --- batch_tte= 141\n",
      "batch event= 0 --- batch_data_length= 27 --- batch_tte= 27\n",
      "batch event= 0 --- batch_data_length= 61 --- batch_tte= 61\n",
      "batch event= 0 --- batch_data_length= 17 --- batch_tte= 17\n",
      "batch event= 0 --- batch_data_length= 31 --- batch_tte= 31\n",
      "batch event= 0 --- batch_data_length= 36 --- batch_tte= 36\n"
     ]
    }
   ],
   "source": [
    "batch_data, batch_data_length, batch_event, batch_tte = next(iter(data_loader))\n",
    "\n",
    "for i in range(min(BATCH_SIZE, 16)):\n",
    "    print(\"batch event= %d --- batch_data_length= %d --- batch_tte= %d\" % (batch_event[i], batch_data_length[i], batch_tte[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sample (that is possibly in training set right now :p )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset will contain 1 samples\n",
      "This dataloader will deliver 1 batches\n",
      "batch event= 0 --- batch_data_length= 26 --- batch_tte= 26\n"
     ]
    }
   ],
   "source": [
    "frac_cases=0.00004\n",
    "\n",
    "FREDDIEMAC_raw_dataset = FREDDIEMAC_basline_dataset(df_blumenstock, \n",
    "                                                    allowed_covariates,\n",
    "                                                    TIME_TO_EVENT_covariate,\n",
    "                                                    LABEL_covariate,\n",
    "                                                    frac_cases,\n",
    "                                                    random_state,\n",
    "                                                    test_set,\n",
    "                                                    augment,\n",
    "                                                    data_augment_factor)\n",
    "\n",
    "test_data_loader = FREDDIEMAC_dataloader(dataset=FREDDIEMAC_raw_dataset, batch_size=1)\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte = next(iter(test_data_loader))\n",
    "print(\"This dataset will contain %d samples\" % len(FREDDIEMAC_raw_dataset))\n",
    "print(\"This dataloader will deliver %d batches\" % test_data_loader.get_max_iterations())\n",
    "print(\"batch event= %d --- batch_data_length= %d --- batch_tte= %d\" % (test_batch_event[0], test_batch_data_length[0], test_batch_tte[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from deepHit import Encoder, CauseSpecificSubnetwork, DeepHit\n",
    "from baseline_losses import loss_1_batch, loss_2_batch\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "LEARNING_RATE_ENCODER = 1e-3\n",
    "LEARNING_RATE_CAUSESS = 1e-3\n",
    "\n",
    "LOSS_1_AMPLIFIER = 1\n",
    "LOSS_2_AMPLIFIER = 1\n",
    "\n",
    "RUN_VALIDATION_ROUND = False\n",
    "VAL_NUM_CASES_RUNTIME = BATCH_SIZE\n",
    "\n",
    "input_size = FREDDIEMAC_raw_dataset.get_num_covariates()\n",
    "output_size = FREDDIEMAC_raw_dataset.get_num_covariates()\n",
    "MAX_LENGTH = FREDDIEMAC_raw_dataset.get_max_length()\n",
    "NUM_CAUSES = 3\n",
    "hidden_size_encoder = 512\n",
    "context_size = 256\n",
    "hidden_cause_size = 512\n",
    "SIGMA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "encoder = Encoder(input_size, hidden_size_encoder, context_size).to(DEVICE)\n",
    "causess = CauseSpecificSubnetwork(context_size, hidden_cause_size, input_size, MAX_LENGTH, NUM_CAUSES).to(DEVICE)\n",
    "DHT = DeepHit(encoder, causess, DEVICE)\n",
    "\n",
    "# intialize optimizer\n",
    "optimizer_encoder = Adam(encoder.parameters(), lr=LEARNING_RATE_ENCODER)\n",
    "optimizer_causess = Adam(causess.parameters(), lr=LEARNING_RATE_CAUSESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a sample before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample has length 26\n",
      "the model predicts the event 2 at time 14\n",
      "probability of prepay event = 0.04\n",
      "probability of default event = 0.04\n",
      "probability of full repay event = 0.04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plot_fht_and_cif_baseline\n",
    "from baseline_losses import CIF_K\n",
    "\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte = next(iter(test_data_loader))\n",
    "\n",
    "test_batch_data = test_batch_data.unsqueeze(0).to(DEVICE)\n",
    "test_batch_data_length = test_batch_data_length.unsqueeze(0).to(DEVICE)\n",
    "test_batch_event = test_batch_event.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "DHT.eval()\n",
    "\n",
    "test_first_hitting_time = DHT(test_batch_data, test_batch_data_length)\n",
    "print(\"sample has length %d\" % test_batch_data_length[0])\n",
    "\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax().item()\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction, model_tte_prediction + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K(test_first_hitting_time[0], 0, MAX_LENGTH)[23].item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K(test_first_hitting_time[0], 1, MAX_LENGTH)[23].item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K(test_first_hitting_time[0], 2, MAX_LENGTH)[23].item())\n",
    "\n",
    "plot_fht_and_cif_baseline(test_first_hitting_time[0], MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss1': 1449.4342041015625, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1442.89111328125, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1431.0067138671875, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1404.2247314453125, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1349.435791015625, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1256.455322265625, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1179.992919921875, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1203.9754638671875, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1143.074951171875, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1099.81787109375, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1090.565673828125, 'train_loss2': 123.984375}\n",
      "{'train_loss1': 1094.1580810546875, 'train_loss2': 123.984375}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c00261523958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marij\\miniconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marij\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PATH = \"/content/gdrive/MyDrive/MP FEB/Colab/models/baseline_model_v4.pth\"\n",
    "\n",
    "train_data_loader = data_loader\n",
    "\n",
    "# start training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  epoch_loss = 0\n",
    "\n",
    "  for batch_number in range(len(train_data_loader)):\n",
    "    data = next(train_data_loader)\n",
    "\n",
    "    batch_loss = 0\n",
    "\n",
    "    optimizer_encoder.zero_grad()\n",
    "    optimizer_causess.zero_grad()\n",
    "\n",
    "    batch_data, batch_data_length, batch_event, batch_tte = data\n",
    "    batch_data = batch_data.to(DEVICE)\n",
    "    batch_data_length = batch_data_length.to(DEVICE)\n",
    "    batch_event = batch_event.to(DEVICE)\n",
    "    batch_tte = batch_tte.to(DEVICE)\n",
    "    \n",
    "    first_hitting_time_batch = DHT(batch_data, batch_data_length)\n",
    "\n",
    "    loss1 = LOSS_1_AMPLIFIER*loss_1_batch(first_hitting_time_batch, batch_event, batch_tte, MAX_LENGTH, DEVICE)\n",
    "    loss2 = LOSS_2_AMPLIFIER*loss_2_batch(first_hitting_time_batch, batch_event, batch_tte, NUM_CAUSES, MAX_LENGTH, SIGMA, DEVICE)\n",
    "\n",
    "    batch_loss = loss1 + loss2\n",
    "    batch_loss.backward()\n",
    "\n",
    "    epoch_loss += batch_loss.detach()\n",
    "\n",
    "    #wandb.log({\"train_loss1\": loss1.item(), \"train_loss2\": loss2.item()})\n",
    "    print({\"train_loss1\": loss1.item(), \"train_loss2\": loss2.item()})\n",
    "\n",
    "    optimizer_encoder.step()\n",
    "    optimizer_causess.step()\n",
    "\n",
    "    # if batch_number % 2**8 == 0:\n",
    "    #   torch.save(DHT.state_dict(), PATH)\n",
    "\n",
    "#   if RUN_VALIDATION_ROUND:\n",
    "#     # validating round\n",
    "#     DHT.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#       val_poc_raw_dataset = PocDataset(num_cases=VAL_NUM_CASES_RUNTIME)\n",
    "#       val_data_loader = torch.utils.data.DataLoader(val_poc_raw_dataset,batch_size=VAL_NUM_CASES_RUNTIME)\n",
    "#       val_batch_data, val_data_length, val_batch_event, val_batch_tte, _ = next(iter(val_data_loader))\n",
    "#       val_batch_data = val_batch_data.to(DEVICE)\n",
    "#       val_data_length = val_data_length.to(DEVICE)\n",
    "#       val_batch_event = val_batch_event.to(DEVICE)\n",
    "#       val_batch_tte = val_batch_tte.to(DEVICE)\n",
    "\n",
    "#       val_first_hitting_time_batch = DHT(val_batch_data, val_data_length)\n",
    "\n",
    "#       val_loss1 = LOSS_1_AMPLIFIER*loss_1_batch(val_first_hitting_time_batch, val_batch_event, val_batch_tte, MAX_LENGTH, DEVICE)/VAL_NUM_CASES_RUNTIME\n",
    "#       val_loss2 = LOSS_2_AMPLIFIER*loss_2_batch(val_first_hitting_time_batch, val_batch_event, val_batch_tte, NUM_CAUSES, MAX_LENGTH, SIGMA, DEVICE)/VAL_NUM_CASES_RUNTIME\n",
    "\n",
    "#       wandb.log({\"val_loss1\": val_loss1.item(), \"val_loss2\": val_loss2.item()})\n",
    "#       wandb.log({\"train_epoch_loss\" : epoch_loss.item(), \"val_epoch_loss\" : val_loss1.item() + val_loss2.item(),\"epoch\": epoch})\n",
    "\n",
    "#     DHT.train()\n",
    "#     # end validating round\n",
    "\n",
    "  #torch.save(DHT.state_dict(), PATH)\n",
    "\n",
    "#wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_fht_and_cif_baseline\n",
    "from baseline_losses import CIF_K\n",
    "\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte = next(iter(test_data_loader))\n",
    "test_batch_data = test_batch_data.unsqueeze(0).to(DEVICE)\n",
    "test_batch_data_length = test_batch_data_length.unsqueeze(0).to(DEVICE)\n",
    "test_batch_event = test_batch_event.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "DHT.eval()\n",
    "\n",
    "test_first_hitting_time = DHT(test_batch_data, test_batch_data_length)\n",
    "print(\"sample has length %d\" % test_batch_data_length[0])\n",
    "\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax().item()\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction, model_tte_prediction + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K(test_first_hitting_time[0], 0, MAX_LENGTH)[23].item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K(test_first_hitting_time[0], 1, MAX_LENGTH)[23].item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K(test_first_hitting_time[0], 2, MAX_LENGTH)[23].item())\n",
    "\n",
    "plot_fht_and_cif_baseline(test_first_hitting_time[0], MAX_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e97b579e8c0e40da8e2bba439fcd59aed88dbd21d3c026977017f366946867"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
