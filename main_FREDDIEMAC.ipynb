{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# SRC_PATH = '/content/gdrive/MyDrive/MP FEB/FREDDIEMAC'\n",
    "# DATA_SRC_PATH = SRC_PATH + \"/data\"\n",
    "# sys.path.append(SRC_PATH)\n",
    "\n",
    "# !pip install wandb -qqq\n",
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "# !pip install dask[dataframe] -qqq\n",
    "# !pip install fastparquet python-snappy -qqq\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # Set the project where this run will be logged\n",
    "#     project=\"main_FREDDIEMAC\", \n",
    "#     # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "#     #name=\"experiment 1\"\n",
    "#     # Track hyperparameters and run metadata\n",
    "#     #config={\n",
    "#       #\"learning_rate\": 0.02,\n",
    "#       #\"architecture\": \"CNN\",\n",
    "#       #\"dataset\": \"CIFAR-100\",\n",
    "#       #\"epochs\": 10,}\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SRC_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe contains a total of 1734900 entries\n",
      "This dataframe contains a total of 24614 loands\n"
     ]
    }
   ],
   "source": [
    "blumenstock_dynamic_types = {'LOAN_SEQUENCE_NUMBER': str, 'MONTHLY_REPORTING_PERIOD': str,'CURRENT_ACTUAL_UPB': float, 'CURRENT_LOAN_DELINQUENCY_STATUS': float, \n",
    "                    'CURRENT_INTEREST_RATE':float,'ELTV': float ,'LOAN_AGE': float, 'REMAINING_MONTHS_TO_LEGAL_MATURITY': float, 'CREDIT_SCORE': float,\n",
    "                    'DTI': float, 'LTV': float, 'BAL_REPAID': float, \n",
    "                    'LABEL': float, \"TIME_TO_EVENT\": float, 'ORIGINAL_INTEREST_RATE': float, 'ORIGINAL_UPB': float, 'TOTAL_OBSERVED_LENGTH': float}\n",
    "\n",
    "df_blumenstock_dynamic = dd.read_parquet(DATA_SRC_PATH + \"/blumenstock_dynamic_labeled_sample_orig_*.parquet.gzip\")\n",
    "df_blumenstock_dynamic = df_blumenstock_dynamic.astype(blumenstock_dynamic_types)\n",
    "\n",
    "print(\"This dataframe contains a total of %d entries\" % len(df_blumenstock_dynamic))\n",
    "print(\"This dataframe contains a total of %d loands\" % len(df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalising raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_to_normalise = ['CURRENT_ACTUAL_UPB', 'CURRENT_LOAN_DELINQUENCY_STATUS', 'CURRENT_INTEREST_RATE', 'ELTV', 'LOAN_AGE', 'REMAINING_MONTHS_TO_LEGAL_MATURITY', 'CREDIT_SCORE',\n",
    "                            'DTI', 'LTV', 'BAL_REPAID', 'ORIGINAL_INTEREST_RATE', 'ORIGINAL_UPB']\n",
    "\n",
    "df_blumenstoch_dynamic_mean = df_blumenstock_dynamic[covariates_to_normalise].mean().compute()\n",
    "df_blumenstoch_std = df_blumenstock_dynamic[covariates_to_normalise].std().compute()\n",
    "\n",
    "df_blumenstock_dynamic[covariates_to_normalise] = (df_blumenstock_dynamic[covariates_to_normalise] - df_blumenstoch_dynamic_mean) / df_blumenstoch_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Splitting train, validation and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train set contains 287909 entries\n",
      "Total validation set contains 37335 entries\n",
      "Total test set contains 18607 entries\n",
      "------------------------------------------------------------------\n",
      "Total train set contains 4097 loans\n",
      "Total validation set contains 513 loans\n",
      "Total test set contains 257 loans\n"
     ]
    }
   ],
   "source": [
    "#TODO THESE SETS ARE OVERLAPPING!!!\n",
    "\n",
    "AMOUNT_OF_TRAIN_LOANS = 2**12 + 1\n",
    "AMOUNT_OF_VALIDATE_LOANS = 2**9 + 1\n",
    "AMOUNT_OF_TEST_LOANS = 2**8 + 1\n",
    "\n",
    "train_choices = np.random.choice(df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].unique(), AMOUNT_OF_TRAIN_LOANS, replace=False)\n",
    "validate_choices = np.random.choice(df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].unique(), AMOUNT_OF_VALIDATE_LOANS, replace=False)\n",
    "test_choices = np.random.choice(df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].unique(), AMOUNT_OF_TEST_LOANS, replace=False)\n",
    "\n",
    "validate_df_blumenstock = df_blumenstock_dynamic[df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].isin(validate_choices)]\n",
    "train_df_blumenstock = df_blumenstock_dynamic[df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].isin(train_choices)]\n",
    "test_df_blumenstock = df_blumenstock_dynamic[df_blumenstock_dynamic[\"LOAN_SEQUENCE_NUMBER\"].isin(test_choices)]\n",
    "\n",
    "print(\"Total train set contains %d entries\" % len(train_df_blumenstock))\n",
    "print(\"Total validation set contains %d entries\" % len(validate_df_blumenstock))\n",
    "print(\"Total test set contains %d entries\" % len(test_df_blumenstock))\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Total train set contains %d loans\" % len(train_df_blumenstock[\"LOAN_SEQUENCE_NUMBER\"].unique()))\n",
    "print(\"Total validation set contains %d loans\" % len(validate_df_blumenstock[\"LOAN_SEQUENCE_NUMBER\"].unique()))\n",
    "print(\"Total test set contains %d loans\" % len(test_df_blumenstock[\"LOAN_SEQUENCE_NUMBER\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size =  128\n",
      "number of covariates =  12\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from FREDDIEMAC_main_data import FREDDIEMAC_main_dataset, FREDDIEMAC_main_dataloader\n",
    "\n",
    "BATCH_SIZE = 2**7\n",
    "\n",
    "allowed_covariates = ['CURRENT_ACTUAL_UPB', 'CURRENT_LOAN_DELINQUENCY_STATUS', 'CURRENT_INTEREST_RATE', 'ELTV', \n",
    "                             'LOAN_AGE', 'REMAINING_MONTHS_TO_LEGAL_MATURITY', 'CREDIT_SCORE', 'DTI', 'LTV', 'BAL_REPAID', \n",
    "                             'ORIGINAL_INTEREST_RATE', 'ORIGINAL_UPB']\n",
    "\n",
    "TOTAL_OBSERVED_LENGTH_covariate = 'TOTAL_OBSERVED_LENGTH'\n",
    "TIME_TO_EVENT_covariate ='TIME_TO_EVENT'\n",
    "LABEL_covariate = 'LABEL'\n",
    "\n",
    "random_state = 123\n",
    "augment = False\n",
    "data_augment_factor = 3\n",
    "\n",
    "print(\"batch_size = \", BATCH_SIZE)\n",
    "print(\"number of covariates = \", len(allowed_covariates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Creating train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset will contain 16388 samples\n",
      "This dataloader will deliver 128 batches\n",
      "torch.Size([128, 180, 12])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "augment_train_data = True\n",
    "\n",
    "train_FREDDIEMAC_raw_dataset = FREDDIEMAC_main_dataset(train_df_blumenstock, \n",
    "                                                        allowed_covariates,\n",
    "                                                        TIME_TO_EVENT_covariate,\n",
    "                                                        TOTAL_OBSERVED_LENGTH_covariate,\n",
    "                                                        LABEL_covariate,\n",
    "                                                        frac_cases=1,\n",
    "                                                        random_state=random_state,\n",
    "                                                        test_set=False,\n",
    "                                                        augment=augment_train_data,\n",
    "                                                        data_augment_factor=data_augment_factor)\n",
    "\n",
    "print(\"This dataset will contain %d samples\" % len(train_FREDDIEMAC_raw_dataset))\n",
    "train_data_loader = FREDDIEMAC_main_dataloader(dataset=train_FREDDIEMAC_raw_dataset, batch_size=BATCH_SIZE)\n",
    "print(\"This dataloader will deliver %d batches\" % train_data_loader.get_max_iterations())\n",
    "batch_data, batch_data_length, batch_event, batch_tte = next(train_data_loader)\n",
    "\n",
    "print(batch_data.shape)\n",
    "print(batch_data_length.shape)\n",
    "print(batch_event.shape)\n",
    "print(batch_tte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Creating validate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset will contain 513 samples\n",
      "This dataloader will deliver 4 batches\n",
      "torch.Size([128, 180, 12])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "augment_validate_data = False\n",
    "\n",
    "validate_FREDDIEMAC_raw_dataset = FREDDIEMAC_main_dataset(validate_df_blumenstock, \n",
    "                                                            allowed_covariates,\n",
    "                                                            TIME_TO_EVENT_covariate,\n",
    "                                                            TOTAL_OBSERVED_LENGTH_covariate,\n",
    "                                                            LABEL_covariate,\n",
    "                                                            frac_cases=1,\n",
    "                                                            random_state=random_state,\n",
    "                                                            test_set=False,\n",
    "                                                            augment=augment_validate_data,\n",
    "                                                            data_augment_factor=data_augment_factor)\n",
    "\n",
    "print(\"This dataset will contain %d samples\" % len(validate_FREDDIEMAC_raw_dataset))\n",
    "validate_data_loader = FREDDIEMAC_main_dataloader(dataset=validate_FREDDIEMAC_raw_dataset, batch_size=BATCH_SIZE)\n",
    "print(\"This dataloader will deliver %d batches\" % validate_data_loader.get_max_iterations())\n",
    "batch_data, batch_data_length, batch_event, batch_tte = next(validate_data_loader)\n",
    "\n",
    "print(batch_data.shape)\n",
    "print(batch_data_length.shape)\n",
    "print(batch_event.shape)\n",
    "print(batch_tte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Creating a test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset will contain 257 samples\n",
      "This dataloader will deliver 2 batches\n",
      "torch.Size([128, 180, 12])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "augment_test_data = False\n",
    "\n",
    "test_FREDDIEMAC_raw_dataset = FREDDIEMAC_main_dataset(test_df_blumenstock, \n",
    "                                                    allowed_covariates,\n",
    "                                                    TIME_TO_EVENT_covariate,\n",
    "                                                    TOTAL_OBSERVED_LENGTH_covariate,\n",
    "                                                    LABEL_covariate,\n",
    "                                                    frac_cases=1,\n",
    "                                                    random_state=random_state,\n",
    "                                                    test_set=False,\n",
    "                                                    augment=augment_test_data,\n",
    "                                                    data_augment_factor=data_augment_factor)\n",
    "\n",
    "print(\"This dataset will contain %d samples\" % len(test_FREDDIEMAC_raw_dataset))\n",
    "test_data_loader = FREDDIEMAC_main_dataloader(dataset=test_FREDDIEMAC_raw_dataset, batch_size=BATCH_SIZE)\n",
    "print(\"This dataloader will deliver %d batches\" % test_data_loader.get_max_iterations())\n",
    "batch_data, batch_data_length, batch_event, batch_tte = next(test_data_loader)\n",
    "\n",
    "print(batch_data.shape)\n",
    "print(batch_data_length.shape)\n",
    "print(batch_event.shape)\n",
    "print(batch_tte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch event= 0 --- batch_data_length= 20 --- batch_tte= 20\n",
      "batch event= 0 --- batch_data_length= 21 --- batch_tte= 40\n",
      "batch event= 3 --- batch_data_length= 124 --- batch_tte= 124\n",
      "batch event= 0 --- batch_data_length= 13 --- batch_tte= 105\n",
      "batch event= 0 --- batch_data_length= 78 --- batch_tte= 90\n",
      "batch event= 0 --- batch_data_length= 82 --- batch_tte= 84\n",
      "batch event= 0 --- batch_data_length= 18 --- batch_tte= 27\n",
      "batch event= 0 --- batch_data_length= 18 --- batch_tte= 18\n",
      "batch event= 0 --- batch_data_length= 90 --- batch_tte= 106\n",
      "batch event= 0 --- batch_data_length= 31 --- batch_tte= 87\n",
      "batch event= 0 --- batch_data_length= 50 --- batch_tte= 111\n",
      "batch event= 0 --- batch_data_length= 85 --- batch_tte= 85\n",
      "batch event= 0 --- batch_data_length= 21 --- batch_tte= 37\n",
      "batch event= 3 --- batch_data_length= 122 --- batch_tte= 122\n",
      "batch event= 0 --- batch_data_length= 53 --- batch_tte= 74\n",
      "batch event= 0 --- batch_data_length= 38 --- batch_tte= 38\n"
     ]
    }
   ],
   "source": [
    "batch_data, batch_data_length, batch_event, batch_tte = next(iter(train_data_loader))\n",
    "\n",
    "for i in range(min(BATCH_SIZE, 16)):\n",
    "    print(\"batch event= %d --- batch_data_length= %d --- batch_tte= %d\" % (batch_event[i], batch_data_length[i], batch_tte[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "from dynamicDeepHit import EncoderRNN, AttnDecoderRNN, CauseSpecificSubnetwork, DynamicDeepHit\n",
    "from losses import loss_1_batch, loss_2_batch, loss_3_batch\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "LEARNING_RATE_ENCODER = 0.001\n",
    "LEARNING_RATE_DECODER = 0.001\n",
    "LEARNING_RATE_CAUSESS = 0.0005\n",
    "\n",
    "LOSS_1_AMPLIFIER = 1\n",
    "LOSS_2_AMPLIFIER = 1\n",
    "LOSS_3_AMPLIFIER = 1\n",
    "\n",
    "RUN_VALIDATION_ROUND = True\n",
    "RUN_VALIDATION_ROUND_BATCHES_THRESHOLD = 2**2\n",
    "VAL_NUM_CASES_RUNTIME = BATCH_SIZE\n",
    "\n",
    "input_size = train_FREDDIEMAC_raw_dataset.get_num_covariates()\n",
    "output_size = train_FREDDIEMAC_raw_dataset.get_num_covariates()\n",
    "MAX_LENGTH = train_FREDDIEMAC_raw_dataset.get_max_length()\n",
    "\n",
    "NUM_CAUSES = 3\n",
    "hidden_size_encoder = 256\n",
    "hidden_size_attention = 512\n",
    "fc_size_encoder = 512\n",
    "SIGMA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "encoder = EncoderRNN(input_size, hidden_size_encoder, fc_size_encoder).to(DEVICE)\n",
    "decoder = AttnDecoderRNN(hidden_size_encoder, hidden_size_attention, output_size).to(DEVICE)\n",
    "causess = CauseSpecificSubnetwork(hidden_size_encoder, input_size, MAX_LENGTH, NUM_CAUSES).to(DEVICE)\n",
    "DDHT = DynamicDeepHit(encoder, decoder, causess, MAX_LENGTH, DEVICE)\n",
    "\n",
    "# intialize optimizer\n",
    "optimizer_encoder = Adam(encoder.parameters(), lr=LEARNING_RATE_ENCODER)\n",
    "optimizer_decoder = Adam(decoder.parameters(), lr=LEARNING_RATE_DECODER)\n",
    "optimizer_causess = Adam(causess.parameters(), lr=LEARNING_RATE_CAUSESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Testing a sample before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first sample of the test batch:\n",
      "sample has length 121\n",
      "the model predicts the event 0 at time 9\n",
      "probability of prepay event = 0.34\n",
      "probability of default event = 0.33\n",
      "probability of full repay event = 0.33\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plot_fht_and_cif, plot_fht, plot_cif\n",
    "from losses import CIF_K_tau\n",
    "\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte = next(iter(test_data_loader))\n",
    "\n",
    "test_batch_data = test_batch_data.to(DEVICE)\n",
    "test_batch_data_length = test_batch_data_length.to(DEVICE)\n",
    "test_batch_event = test_batch_event.to(DEVICE)\n",
    "\n",
    "DDHT.eval()\n",
    "\n",
    "test_output, test_first_hitting_time, _ = DDHT(test_batch_data, test_batch_data_length)\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax(dim=1)\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "\n",
    "DDHT.train()\n",
    "\n",
    "print(\"For the first sample of the test batch:\")\n",
    "print(\"sample has length %d\" % test_batch_data_length[0])\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction[0], model_tte_prediction[0] + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 0, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 1, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 2, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "\n",
    "plot_fht_and_cif(test_first_hitting_time[0], test_batch_data_length[0], MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss1': 649.7366333007812, 'train_loss2': 54.74001693725586, 'train_loss3': 0.25241509079933167}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [04:39<9:52:12, 279.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_epoch_val_loss1': 4.928165435791016, 'val_epoch_val_loss2': 0.4657089412212372, 'val_epoch_val_loss3': 0.03410137817263603}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/128 [06:03<7:43:59, 220.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss1': 648.639892578125, 'train_loss2': 54.72222137451172, 'train_loss3': 0.243561789393425}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/128 [07:28<6:15:07, 180.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss1': 647.5283203125, 'train_loss2': 54.70493698120117, 'train_loss3': 0.23538409173488617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [08:55<5:14:50, 152.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss1': 646.3473510742188, 'train_loss2': 54.68513870239258, 'train_loss3': 0.22622427344322205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [09:09<4:44:08, 137.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4e05349ec36e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOSS_1_AMPLIFIER\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_1_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_event\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_tte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mloss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOSS_2_AMPLIFIER\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_2_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_event\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_tte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CAUSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSIGMA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mloss3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOSS_3_AMPLIFIER\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_3_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marij\\Desktop\\THESIS ECO\\DDHT\\DDHT_pytorch\\losses.py\u001b[0m in \u001b[0;36mloss_2_batch\u001b[1;34m(first_hitting_time_batch, event_batch, batch_tte, batch_data_length, num_events, max_length, sigma, device)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mcif_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_hitting_time\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mcif_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCIF_K\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data_length\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# get the CIF where our event equals the one we're considering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marij\\Desktop\\THESIS ECO\\DDHT\\DDHT_pytorch\\losses.py\u001b[0m in \u001b[0;36mCIF_K\u001b[1;34m(first_hitting_time, event_k, data_length, MAX_LENGTH)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mcif_k\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCIF_K_tau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcif_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marij\\Desktop\\THESIS ECO\\DDHT\\DDHT_pytorch\\losses.py\u001b[0m in \u001b[0;36mCIF_K_tau\u001b[1;34m(first_hitting_time, event_k, tte, data_length, MAX_LENGTH)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#event_time is on index \"data_length\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mamount_of_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_hitting_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamount_of_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtte\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdenomenator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_hitting_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamount_of_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#print(\"numerator=\", numerator)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "#PATH = \"/content/gdrive/MyDrive/MP FEB/FREDDIEMAC/models/main_model_v1.pth\"\n",
    "\n",
    "# start training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "  epoch_loss = 0\n",
    "  train_epoch_val_loss = 0\n",
    "  train_epoch_val_loss1 = 0\n",
    "  train_epoch_val_loss2 = 0\n",
    "\n",
    "  for batch_number in trange(len(train_data_loader)):\n",
    "    data = next(train_data_loader)\n",
    "\n",
    "    batch_loss = 0\n",
    "\n",
    "    optimizer_encoder.zero_grad()\n",
    "    optimizer_decoder.zero_grad()\n",
    "    optimizer_causess.zero_grad()\n",
    "\n",
    "    batch_data, batch_data_length, batch_event, batch_tte = data\n",
    "    batch_data = batch_data.to(DEVICE)\n",
    "    batch_data_length = batch_data_length.to(DEVICE)\n",
    "    batch_event = batch_event.to(DEVICE)\n",
    "    batch_tte = batch_tte.to(DEVICE)\n",
    "    \n",
    "    output_batch, first_hitting_time_batch, _ = DDHT(batch_data, batch_data_length)\n",
    "\n",
    "    loss1 = LOSS_1_AMPLIFIER*loss_1_batch(first_hitting_time_batch, batch_event, batch_tte, batch_data_length, MAX_LENGTH, DEVICE)\n",
    "    loss2 = LOSS_2_AMPLIFIER*loss_2_batch(first_hitting_time_batch, batch_event, batch_tte, batch_data_length, NUM_CAUSES, MAX_LENGTH, SIGMA, DEVICE)\n",
    "    loss3 = LOSS_3_AMPLIFIER*loss_3_batch(output_batch, batch_data.detach())\n",
    "\n",
    "    batch_loss = loss1 + loss2 + loss3\n",
    "    batch_loss.backward()\n",
    "\n",
    "    epoch_loss += batch_loss.detach()\n",
    "\n",
    "    #wandb.log({\"train_loss1\": loss1.item(), \"train_loss2\": loss2.item(), \"train_loss3\": loss3.item()})\n",
    "    print({\"train_loss1\": loss1.item(), \"train_loss2\": loss2.item(), \"train_loss3\": loss3.item()})\n",
    "\n",
    "    optimizer_encoder.step()\n",
    "    optimizer_decoder.step()\n",
    "    optimizer_causess.step()\n",
    "\n",
    "    if RUN_VALIDATION_ROUND and batch_number % 5 == 0:\n",
    "      # validation round\n",
    "      # torch.save(DDHT.state_dict(), PATH)\n",
    "      DDHT.eval()\n",
    "\n",
    "      val_epoch_val_loss = 0\n",
    "      val_epoch_val_loss1 = 0\n",
    "      val_epoch_val_loss2 = 0\n",
    "      val_epoch_val_loss3 = 0\n",
    "\n",
    "      VAL_NUM_CASES_RUNTIME = len(validate_data_loader)*BATCH_SIZE\n",
    "      for validation_batch_number in range(len(validate_data_loader)):\n",
    "        data = next(validate_data_loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          val_batch_data, val_batch_data_length, val_batch_event, val_batch_tte = next(iter(validate_data_loader))\n",
    "          val_batch_data = val_batch_data.to(DEVICE)\n",
    "          val_batch_data_length = val_batch_data_length.to(DEVICE)\n",
    "          val_batch_event = val_batch_event.to(DEVICE)\n",
    "          val_batch_tte = val_batch_tte.to(DEVICE)\n",
    "\n",
    "          val_output_batch, val_first_hitting_time_batch, _ = DDHT(val_batch_data, val_batch_data_length)\n",
    "\n",
    "          val_loss1 = LOSS_1_AMPLIFIER*loss_1_batch(val_first_hitting_time_batch, val_batch_event, val_batch_tte, val_batch_data_length, MAX_LENGTH, DEVICE)/VAL_NUM_CASES_RUNTIME\n",
    "          val_loss2 = LOSS_2_AMPLIFIER*loss_2_batch(val_first_hitting_time_batch, val_batch_event, val_batch_tte, val_batch_data_length, NUM_CAUSES, MAX_LENGTH, SIGMA, DEVICE)/VAL_NUM_CASES_RUNTIME\n",
    "          val_loss3 = LOSS_3_AMPLIFIER*loss_3_batch(val_output_batch, val_batch_data.detach())/VAL_NUM_CASES_RUNTIME\n",
    "\n",
    "          val_epoch_val_loss1 += val_loss1\n",
    "          val_epoch_val_loss2 += val_loss2\n",
    "          val_epoch_val_loss3 += val_loss3\n",
    "          val_epoch_val_loss = val_loss1 + val_loss2 + val_loss3\n",
    "\n",
    "      #wandb.log({\"val_epoch_val_loss1\": val_epoch_val_loss1.item(), \"val_epoch_val_loss2\": val_epoch_val_loss2.item(), \"val_epoch_val_loss3\": val_epoch_val_loss3.item(), \"val_epoch_val_loss\": val_epoch_val_loss.item()})\n",
    "      print({\"val_epoch_val_loss1\": val_epoch_val_loss1.item(), \"val_epoch_val_loss2\": val_epoch_val_loss2.item(), \"val_epoch_val_loss3\": val_epoch_val_loss3.item()})\n",
    "\n",
    "      DDHT.train()\n",
    "      # end validating round\n",
    "\n",
    "  #wandb.log({\"train_epoch_loss\": epoch_loss.item()})\n",
    "  #torch.save(DDHT.state_dict(), PATH)\n",
    "\n",
    "#wandb.finish() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"/content/gdrive/MyDrive/MP FEB/FREDDIEMAC/models/main_model_v1.pth\"\n",
    "#torch.save(DDHT.state_dict(), PATH)\n",
    "#DDHT.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Testing a sample after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_fht_and_cif, plot_fht, plot_cif\n",
    "from losses import CIF_K_tau\n",
    "\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte = next(iter(test_data_loader))\n",
    "\n",
    "test_batch_data = test_batch_data.to(DEVICE)\n",
    "test_batch_data_length = test_batch_data_length.to(DEVICE)\n",
    "test_batch_event = test_batch_event.to(DEVICE)\n",
    "\n",
    "DDHT.eval()\n",
    "\n",
    "test_output, test_first_hitting_time, test_attention_weights = DDHT(test_batch_data, test_batch_data_length)\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax(dim=1)\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "\n",
    "print(\"For the first sample of the test batch:\")\n",
    "print(\"sample has length %d\" % test_batch_data_length[0])\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction[0], model_tte_prediction[0] + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 0, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 1, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 2, MAX_LENGTH, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "\n",
    "plot_fht_and_cif(test_first_hitting_time[0], test_batch_data_length[0], MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which attention weights are the most important?\n",
    "\n",
    "from utils import plot_attention_weights\n",
    "plot_attention_weights(test_attention_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking some covariates\n",
    "\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte, test_meta = next(iter(test_data_loader))\n",
    "test_batch_data_length = test_batch_data_length.unsqueeze(0).to(DEVICE)\n",
    "test_batch_event = test_batch_event.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "masked_data = copy.deepcopy(test_batch_data.unsqueeze(0))\n",
    "\n",
    "masked_data[:,:,0] = 0 #Comment this to keep the covariate\n",
    "masked_data[:,:,1] = 0 #Comment this to keep the covariate\n",
    "masked_data[:,:,2] = 0 #Comment this to keep the covariate\n",
    "masked_data[:,:,3] = 0 #Comment this to keep the covariate\n",
    "masked_data[:,:,4] = 0 #Comment this to keep the covariate\n",
    "\n",
    "masked_data = masked_data.to(DEVICE)\n",
    "\n",
    "test_output, test_first_hitting_time, _ = DDHT(masked_data, test_batch_data_length)\n",
    "print(\"sample has length %d\" % test_batch_data_length[0])\n",
    "print(\"sample will experience event %d at time %d, but shows event %d\" % (test_meta['ground_truth_event'], test_meta['age'], test_batch_event[0]))\n",
    "\n",
    "\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax().item()\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction, model_tte_prediction + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 0, 24, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 1, 24, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 2, 24, test_batch_data_length[0], MAX_LENGTH).item())\n",
    "\n",
    "plot_fht_and_cif(test_first_hitting_time[0], test_batch_data_length[0], MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability that this loan will prepay, default or repay in the comming \"delta\" months?\n",
    "\n",
    "delta = 6  #This is variable\n",
    "\n",
    "evaluation_time = min(int(test_batch_data_length[0].item()) + delta, MAX_LENGTH)\n",
    "print(\"In the comming %d months, the probability that a specific event happens is:\" % delta)\n",
    "\n",
    "p_ev0 = CIF_K_tau(test_first_hitting_time[0], 0, evaluation_time, test_batch_data_length[0], MAX_LENGTH).item()\n",
    "p_ev1 = CIF_K_tau(test_first_hitting_time[0], 1, evaluation_time, test_batch_data_length[0], MAX_LENGTH).item()\n",
    "p_ev2 = CIF_K_tau(test_first_hitting_time[0], 2, evaluation_time, test_batch_data_length[0], MAX_LENGTH).item()\n",
    "\n",
    "print(\"probability a prepay happens = %.3f\" % p_ev0)\n",
    "print(\"probability a default happens = %.3f\" % p_ev1)\n",
    "print(\"probability a full repay happens = %.3f\" % p_ev2)\n",
    "\n",
    "sum = p_ev0 + p_ev1 + p_ev2\n",
    "print(\"The probability anything happens = %.3f\" % sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability that this loan will prepay, default or repay with less data\n",
    "test_batch_data, test_batch_data_length, test_batch_event, test_batch_tte, test_meta = next(iter(test_data_loader))\n",
    "\n",
    "delta = 5 #This is variable\n",
    "shortened_length = test_batch_data_length - delta\n",
    "shortened_test_batch_data = copy.deepcopy(test_batch_data)\n",
    "shortened_test_batch_data[shortened_length:test_batch_data_length] = torch.zeros(delta, input_size)\n",
    "shortened_test_batch_data_length = copy.deepcopy(shortened_length)\n",
    "\n",
    "shortened_test_batch_data = shortened_test_batch_data.unsqueeze(0).to(DEVICE)\n",
    "shortened_test_batch_data_length = shortened_test_batch_data_length.unsqueeze(0).to(DEVICE)\n",
    "test_batch_event = test_batch_event.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "test_output, test_first_hitting_time, _ = DDHT(shortened_test_batch_data, shortened_test_batch_data_length)\n",
    "print(\"sample has length %d, but we concatenated to %d\" % (test_batch_data_length, shortened_test_batch_data_length[0]))\n",
    "print(\"sample will experience event %d at time %d, but shows event %d\" % (test_meta['ground_truth_event'], test_meta['age'], test_batch_event[0]))\n",
    "\n",
    "\n",
    "test_first_hitting_time_argmax = test_first_hitting_time.argmax().item()\n",
    "model_event_prediction = test_first_hitting_time_argmax // MAX_LENGTH\n",
    "model_tte_prediction = test_first_hitting_time_argmax % MAX_LENGTH\n",
    "print(\"the model predicts the event %d at time %d\" % (model_event_prediction, model_tte_prediction + 1))\n",
    "\n",
    "print(\"probability of prepay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 0, 24, shortened_test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of default event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 1, 24, shortened_test_batch_data_length[0], MAX_LENGTH).item())\n",
    "print(\"probability of full repay event = %.2f\" % CIF_K_tau(test_first_hitting_time[0], 2, 24, shortened_test_batch_data_length[0], MAX_LENGTH).item())\n",
    "\n",
    "plot_fht_and_cif(test_first_hitting_time[0], shortened_test_batch_data_length[0], MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_gamma\n",
    "\n",
    "SENSITIVITY_BATCH_SIZE = 2**8\n",
    "\n",
    "sensitivity_poc_dataset = PocDataset(num_cases=SENSITIVITY_BATCH_SIZE, test_set=True, repays=True, augment=False)\n",
    "sensitivity_data_loader = DataLoader(dataset=sensitivity_poc_dataset, batch_size=SENSITIVITY_BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "delta = 6 #This is variable\n",
    "\n",
    "min_gamma = torch.zeros(NUM_CAUSES, input_size)\n",
    "max_gamma = torch.zeros(NUM_CAUSES, input_size)\n",
    "\n",
    "for covariate_index in range(input_size):\n",
    "    sensitivity_batch_data, sensitivity_batch_data_length, sensitivity_batch_event, sensitivity_batch_tte, sensitivity_meta = next(iter(sensitivity_data_loader))\n",
    "\n",
    "    #assuming it's minimum & maximum from the whole batch, not from a single sample\n",
    "    batch_min = torch.tensor(float('Inf'))\n",
    "    batch_max = (-1)*torch.tensor(float('Inf'))\n",
    "\n",
    "    #we have to iterate over it otherwise, we catch the zero's that are meant as NANs in our case\n",
    "    for sample, data_length in zip(sensitivity_batch_data, sensitivity_batch_data_length):\n",
    "        sample_min = torch.min(sample[:data_length,covariate_index])\n",
    "        sample_max = torch.max(sample[:data_length,covariate_index])\n",
    "\n",
    "        if sample_min < batch_min:\n",
    "            batch_min = sample_min\n",
    "\n",
    "        if sample_max > batch_max:\n",
    "            batch_max = sample_max\n",
    "\n",
    "    min_sensitivity_batch_data = copy.deepcopy(sensitivity_batch_data)\n",
    "    max_sensitivity_batch_data = copy.deepcopy(sensitivity_batch_data)\n",
    "\n",
    "    #for safety we iterate again, since we otherwise fill in the zero's that are meant as NANs\n",
    "    for sample_index, data_length in enumerate(sensitivity_batch_data_length):\n",
    "        min_sensitivity_batch_data[sample_index,:data_length, covariate_index] = batch_min\n",
    "        max_sensitivity_batch_data[sample_index,:data_length, covariate_index] = batch_max\n",
    "\n",
    "    min_sensitivity_batch_data = min_sensitivity_batch_data.to(DEVICE)\n",
    "    max_sensitivity_batch_data = max_sensitivity_batch_data.to(DEVICE)\n",
    "    sensitivity_batch_data_length = sensitivity_batch_data_length.to(DEVICE)\n",
    "\n",
    "    #for safety we iterate again, because the previous iteration might be absorbed by the one above that\n",
    "    for sample_index, data_length in enumerate(sensitivity_batch_data_length):\n",
    "        for cause_index in range(NUM_CAUSES):\n",
    "            evaluation_time = min(int(data_length.item()) + delta, MAX_LENGTH)\n",
    "\n",
    "            _, max_fht, _ = DDHT(max_sensitivity_batch_data[sample_index].unsqueeze(0), data_length)\n",
    "            _, min_fht, _ = DDHT(min_sensitivity_batch_data[sample_index].unsqueeze(0), data_length)\n",
    "\n",
    "            max_gamma[cause_index, covariate_index] += CIF_K_tau(max_fht[0], cause_index, evaluation_time, data_length, MAX_LENGTH).item()\n",
    "            min_gamma[cause_index, covariate_index] += CIF_K_tau(min_fht[0], cause_index, evaluation_time, data_length, MAX_LENGTH).item()\n",
    "\n",
    "\n",
    "gamma = (1/SENSITIVITY_BATCH_SIZE)*(min_gamma - max_gamma)\n",
    "plot_gamma(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_attention_weights_batch\n",
    "\n",
    "ATTENTION_BATCH_SIZE = 2**8\n",
    "\n",
    "attention_poc_dataset = PocDataset(num_cases=ATTENTION_BATCH_SIZE, test_set=True, repays=True, augment=False)\n",
    "attention_data_loader = DataLoader(dataset=attention_poc_dataset, batch_size=ATTENTION_BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "attention_batch_data, attention_batch_data_length, _, _, _ = next(iter(attention_data_loader))\n",
    "attention_batch_data = attention_batch_data.to(DEVICE)\n",
    "attention_batch_data_length = attention_batch_data_length.to(DEVICE)\n",
    "\n",
    "_, _, attention_weights_batch = DDHT(attention_batch_data, attention_batch_data_length)\n",
    "\n",
    "plot_attention_weights_batch(attention_weights_batch, attention_batch_data_length, normalised=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e97b579e8c0e40da8e2bba439fcd59aed88dbd21d3c026977017f366946867"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
